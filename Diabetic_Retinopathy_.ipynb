{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9D9xusMCktT"
      },
      "source": [
        "# **STEP 1: Mount Drive and Setup Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MDIf_AfCbDj",
        "outputId": "4fb9b5c2-6c9e-4d78-f8f1-8febaa6fb309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current directory: /content/drive/MyDrive/octdataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "project_path = \"/content/drive/MyDrive/octdataset\"\n",
        "os.chdir(project_path)\n",
        "print(\"Current directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7sl5zN0Og_r"
      },
      "source": [
        "# **STEP 2: Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QFYDSyfOeMI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "import seaborn as sns\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_5ro_8Ov8R"
      },
      "source": [
        "# **STEP 3: Load OCT + Fundus Image Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjvNSZ4POtv7"
      },
      "outputs": [],
      "source": [
        "oct_folder = \"/content/drive/MyDrive/octdataset/OCT/OCT_NEW\"\n",
        "fundus_folder = \"/content/drive/MyDrive/octdataset/eye fundus (2)/eye fundus\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8urWCzrO2iH"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder, label, img_size=128, limit=None):\n",
        "    images, labels = [], []\n",
        "    count = 0\n",
        "    for root, _, files in os.walk(folder):\n",
        "        for img_name in files:\n",
        "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.bmp')):\n",
        "                img_path = os.path.join(root, img_name)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "                    img = cv2.resize(img, (img_size, img_size))\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    count += 1\n",
        "                    if limit and count >= limit:\n",
        "                        return np.array(images), np.array(labels)\n",
        "                except Exception as e:\n",
        "                    print(\"Error loading:\", img_path, e)\n",
        "                    continue\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBbvDbz6O36n"
      },
      "outputs": [],
      "source": [
        "# Load OCT (label 0) and Fundus (label 1)\n",
        "oct_images, oct_labels = load_images_from_folder(oct_folder, label=0)\n",
        "fundus_images, fundus_labels = load_images_from_folder(fundus_folder, label=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm-XM055O5sd"
      },
      "outputs": [],
      "source": [
        "# Combine images and labels\n",
        "images = np.concatenate((oct_images, fundus_images), axis=0) / 255.0\n",
        "labels = np.concatenate((oct_labels, fundus_labels), axis=0)\n",
        "\n",
        "print(f\"Total images: {images.shape}, Total labels: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlOaqb3sO8-z"
      },
      "source": [
        "# **STEP 4: Feature Extraction using VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVN4dmn7O7bJ"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\n",
        "model = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
        "\n",
        "print(\"Extracting deep features...\")\n",
        "features = model.predict(images, verbose=1)\n",
        "features = features.reshape(features.shape[0], -1)\n",
        "print(\"Feature shape:\", features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEdACOYzPHEW"
      },
      "source": [
        "# **STEP 5: Train-Test Split (80% train, 20% test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlFpZ9H4PE_P"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6vVN2igPVPM"
      },
      "source": [
        "# **STEP 6: Train LightGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJMRiH8MPSnc"
      },
      "outputs": [],
      "source": [
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=150,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=10,\n",
        "    num_leaves=31,\n",
        "    random_state=42,\n",
        "    force_col_wise=True,\n",
        "    verbosity=-1\n",
        ")\n",
        "lgbm.fit(X_train, y_train)\n",
        "lgbm_pred = lgbm.predict(X_test)\n",
        "lgbm_acc = accuracy_score(y_test, lgbm_pred)\n",
        "print(f\"\\nâœ… LightGBM Accuracy: {lgbm_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbK7u8G-P1xR"
      },
      "outputs": [],
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, lgbm_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, lgbm_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - LightGBM\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyhwsMnhQKM3"
      },
      "source": [
        "# **STEP 7: Upload and Predict User Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ntc7sojP8Jh"
      },
      "outputs": [],
      "source": [
        "# STEP 8: Upload and Predict User Image\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "test_img = cv2.imread(img_path)\n",
        "test_img = cv2.resize(test_img, (128, 128))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "test_img = test_img / 255.0\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "\n",
        "test_features = model.predict(test_img)\n",
        "test_features = test_features.reshape(test_features.shape[0], -1)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "loaded_model = joblib.load(\"best_dr_model.pkl\")\n",
        "pred = loaded_model.predict(test_features)[0]\n",
        "proba = loaded_model.predict_proba(test_features)[0]\n",
        "confidence = np.max(proba) * 100\n",
        "\n",
        "label_map = {0: \"Normal\", 1: \"Moderate\", 2: \"Severe\"}\n",
        "print(f\"\\nðŸ©º Prediction: {label_map.get(pred, 'Unknown')} (Confidence: {confidence:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 8:Images Before and After Preprocessing**"
      ],
      "metadata": {
        "id": "AvFbx43uVIZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaiRRh6fQQLc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8a2WH63QUU3"
      },
      "outputs": [],
      "source": [
        "# Select random samples from OCT and Fundus datasets\n",
        "def show_sample_images(before_images, after_images, title_before, title_after):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(3):\n",
        "        # Before Preprocessing\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(before_images[i])\n",
        "        plt.title(f\"{title_before} {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # After Preprocessing\n",
        "        plt.subplot(2, 3, i+4)\n",
        "        plt.imshow(after_images[i])\n",
        "        plt.title(f\"{title_after} {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6vbSln-QW5c"
      },
      "outputs": [],
      "source": [
        "# Load a few raw images before preprocessing\n",
        "sample_oct_raw = [cv2.imread(os.path.join(oct_folder, img)) for img in os.listdir(oct_folder)[:3]]\n",
        "sample_fundus_raw = [cv2.imread(os.path.join(fundus_folder, img)) for img in os.listdir(fundus_folder)[:3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2GXvx5QQY-A"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to the same images\n",
        "def preprocess_images(image_list, img_size=128):\n",
        "    processed = []\n",
        "    for img in image_list:\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img / 255.0\n",
        "        processed.append(img)\n",
        "    return np.array(processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNpamgByQaZW"
      },
      "outputs": [],
      "source": [
        "sample_oct_processed = preprocess_images(sample_oct_raw)\n",
        "sample_fundus_processed = preprocess_images(sample_fundus_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKuinxRuQb9j"
      },
      "outputs": [],
      "source": [
        "# Display before and after preprocessing\n",
        "print(\"ðŸ“· OCT Images Before and After Preprocessing:\")\n",
        "show_sample_images(sample_oct_raw, sample_oct_processed, \"Before\", \"After\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvIeV-a5Qdmi"
      },
      "outputs": [],
      "source": [
        "print(\"ðŸ“· Fundus Images Before and After Preprocessing:\")\n",
        "show_sample_images(sample_fundus_raw, sample_fundus_processed, \"Before\", \"After\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOangm5eO9JI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}